{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. SVM --> \"Machines à Vecteurs de Support\" ou en Anglais \"Support Vector Machine\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Histoire :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conceptualisé par Vladimir Vapnik dès le début des années 60, il fait son entrée dans le milieu de l’informatique en 1990.<br>  Dès lors, il devient une référence pour tous ceux qui s’intéressent de près ou de loin aux techniques d’apprentissage supervisé. <br> Encore aujourd’hui, il continue d’être enseigné, étudié et massivement utilisé.<br>  Vous l’aurez compris, nous allons parler ici des Machines à Vecteurs de Support, aussi appelé SVM pour Support Vector Machine. \n",
    "* Permet de faire prédiction quantitative ou qualitative "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `Warning : Parler de la simplicité d’un tel algorithme revient à parler de la petitesse de la Lune. ` <br>\n",
    "> ` On sait qu’elle est petite à côté de ce qui l’entoure, mais on pourrait quand même pas en faire le tour à pied.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nous allons vous présenter le principe de base des Margin Classifiers, et les limites de ces derniers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Mathématiques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1°) Margin Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode que l’on va appliquer est la suivante :\n",
    "\n",
    "Tracer une droite séparant les 2 classes.<br> Si l’observation se trouve au-dessus de cette droite, on dira qu’il s’agit d’un “+”, sinon d’un “-”. <br>\n",
    "* Comment on trace la droite : trace la droite qui maximise l'écart entre les différents groupes.\n",
    "* Exemple : on prend le point d'un groupe A le plus proche d'un point le plus proche du groupe B, et le point B le plus proche du point du groupe A. <br> et on trace une droite qui maximise la distance entre les deux points pour que la droite soit au millieu des deux points et que ainsi la capacité de généralisation de l'algo soit optimal.\n",
    "* Soucis lorsque le jeu de donnée n'est pas linéairement séparable : on utilise pour cela l'astuce du noyau.<br> On applique une transofrmation sur nos données pour les rendre linéairement séparable. \n",
    "* AUtres soucis : lorsque l'on a plus de trois types de classes. Solutions :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./droiteclassification.png\" alt=\"drawing\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `En mathématiques, la distance qui sépare une droite de l’observation la plus proche est appelée la marge. ` <br>\n",
    "\n",
    "> `La droite centrale a une marge plus importante que les deux autres. `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode semble fonctionner correctement.<br>\n",
    "Cependant, dans le cas particulier de notre problème, il existe une infinité de droites séparant parfaitement les 2 ensembles.<br>\n",
    "Chacune d’elle délimite des espaces différents et constitue une réponse différente au problème. <br>\n",
    "La question est alors de savoir comment choisir la meilleure droite parmi toutes les droites possibles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./plusieurspossibilite.png\" alt=\"drawing\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `En mathématiques, la distance qui sépare une droite de l’observation la plus proche est appelée la marge.`<br>` La droite centrale a une marge plus importante que les deux autres.`<br>` Autrement dit, la droite qui sépare le mieux les 2 classes est celle dont la marge est la plus élevée. `<br>`Vous comprenez désormais d’où vient le terme de “Maximal Margin Classifiers” ?`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"marge.png\" alt=\"drawing\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le système de marge fonctionne uniquement quand c'est linéaire, exemple quand il s'agit de température à l'année"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2°) les fonctions \"noyau\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour palier ce problème on utilise la technique du noyau, et on applique une transforme pour les linéairement séparable \n",
    "Voici quelques formules pour les noyaux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"plan.png\" alt=\"drawing\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"hyperplan.png\" alt=\"drawing\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noyau linéaire\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://latex.codecogs.com/png.image?\\dpi{110}&space;\\bg_white&space;\\inline&space;K\\left&space;(&space;x,x'&space;\\right&space;)&space;=&space;\\left<&space;x,x'\\right>\" title=\"\\bg_white \\inline K\\left ( x,x' \\right ) = \\left< x,x'\\right>\" width=300 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noyau quadratique homogène "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://latex.codecogs.com/png.image?\\dpi{110}&space;\\bg_white&space;\\inline&space;K\\left&space;(&space;x,x'&space;\\right&space;)&space;=&space;\\left<&space;x,x'\\right>^{2}\" title=\"\\bg_white \\inline K\\left ( x,x' \\right ) = \\left< x,x'\\right>^{2}\"  width=300/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noyau polynomial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://latex.codecogs.com/png.image?\\dpi{110}&space;\\bg_white&space;\\inline&space;K\\left&space;(&space;x,x'&space;\\right&space;)&space;=&space;\\left&space;(\\left<&space;x,x'\\right>&plus;&space;c^{d}&space;&space;\\right&space;)\" title=\"\\bg_white \\inline K\\left ( x,x' \\right ) = \\left (\\left< x,x'\\right>+ c^{d} \\right )\"  width=300/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noyau gaussien"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"noyaugaussien.png\" alt=\"drawing\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noyau RBF (Radial Basis Funtion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"noyau RBF.png\" alt=\"drawing\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Importation des bibliothèques `SVM` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Différente Kernel : Kernel trick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour 1 droite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(kernel='linear')       #utilisation de l'algorithme SVC avec l'utilisation du noyau linéaire kernel{‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’} or callable, default=’rbf’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(kernel='rbf', c=1, gamma=2**-5)     #utilisation de l'algorithme SVC avec l'utilisation du noyau linéaire kernel{‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’} or callable, default=’rbf’\n",
    "\n",
    "# Exemple le gamma est petit, cela sera moins complexe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"svm_kenerl.png\" alt=\"drawing\" width=750/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C parameter par défault est = 1 (comparaison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(kernel='linear', c=2**-5) # Exemple pour avoir avoir un bas parametre, priorisé le soft margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(kernel='linear', c=2**5) # Exemple pour avoir avoir un haut parametre, priorisé quelques erreurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pour gerer quand il y a plus de 2 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(kernel='linear', decision_function_shape='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train)               #entrainement de l'algorithme \n",
    "y_predict = model.predict(X_test)        #prediction des y en fonction des X dans l'algo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avantage et inconvénients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Très bien avec les données avec beaucoup de dimensions.\n",
    "Fonctionne très bien avec les petits dataset pour\n",
    "\n",
    "Choisir le bon kernel et les paramètre peuvent demander beaucoup de temps de calcul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV Ressource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Video Youtube](https://youtu.be/N1vOgolbjSc)\n",
    "\n",
    "[Cours OpenClassRoom](https://openclassrooms.com/fr/courses/4470406-utilisez-des-modeles-supervises-non-lineaires)\n",
    "\n",
    "[Le Fichier PDF](https://eric.univ-lyon2.fr/~ricco/cours/slides/svm.pdf)\n",
    "\n",
    "[SKLEARN](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b5157da187ae8d91b3e4d97a68a452a9b9735ebfc6e86b4654187d15a525e7f9"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 ('envMl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
